{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb276e49-fbf0-4fd1-82aa-419f4aae108a",
   "metadata": {},
   "source": [
    "## Библиотечки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c010fd3-6d02-438d-8b04-18c5c1c5b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  \n",
      "  Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "  This package requires Rust and Cargo to compile extensions. Install it through\n",
      "  the system's package manager or via https://rustup.rs/\n",
      "  \n",
      "  Checking for Rust toolchain....\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade diffusers transformers accelerate invisible_watermark mediapy\n",
    "     \n",
    "\n",
    "use_refiner = False\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb410ecb-1c43-40ca-9c2d-e5c4afcdeab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmedia\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapy'"
     ]
    }
   ],
   "source": [
    "import mediapy as media\n",
    "import random\n",
    "import sys\n",
    "import torch     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ef7f2-15a6-4dcd-b313-3f2fa1261a24",
   "metadata": {},
   "source": [
    "## Пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34567957-fa0d-4f86-ad0c-57640f58e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    "    )\n",
    "\n",
    "if use_refiner:\n",
    "  refiner = DiffusionPipeline.from_pretrained(\n",
    "      \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "      text_encoder_2=pipe.text_encoder_2,\n",
    "      vae=pipe.vae,\n",
    "      torch_dtype=torch.float16,\n",
    "      use_safetensors=True,\n",
    "      variant=\"fp16\",\n",
    "  )\n",
    "\n",
    "  refiner = refiner.to(\"cuda\")\n",
    "\n",
    "  pipe.enable_model_cpu_offload()\n",
    "else:\n",
    "  pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f119010-2460-4c5d-b363-e00e05915f79",
   "metadata": {},
   "source": [
    "## Промпт text-2-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cf0ab0-6190-49f5-b256-897fb6480439",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma lot of cats maine coons\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, sys\u001b[38;5;241m.\u001b[39mmaxsize)\n\u001b[0;32m      4\u001b[0m images \u001b[38;5;241m=\u001b[39m pipe(\n\u001b[0;32m      5\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt,\n\u001b[0;32m      6\u001b[0m     output_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_refiner \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpil\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmanual_seed(seed),\n\u001b[0;32m      8\u001b[0m     )\u001b[38;5;241m.\u001b[39mimages\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_refiner:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = \"a lot of cats maine coons\"\n",
    "seed = random.randint(0, sys.maxsize)\n",
    "\n",
    "images = pipe(\n",
    "    prompt = prompt,\n",
    "    output_type = \"latent\" if use_refiner else \"pil\",\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed),\n",
    "    ).images\n",
    "\n",
    "if use_refiner:\n",
    "  images = refiner(\n",
    "      prompt = prompt,\n",
    "      image = images,\n",
    "      ).images\n",
    "\n",
    "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
    "media.show_images(images)\n",
    "images[0].save(\"output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbf80f-ef8d-45ae-bcad-199492a4585d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2e4f4-4e76-46d2-997f-7a126b08cafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
